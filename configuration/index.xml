<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Configuration on Choria Stream Replicator</title><link>https://choria-io.github.io/stream-replicator/configuration/index.html</link><description>Recent content in Configuration on Choria Stream Replicator</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://choria-io.github.io/stream-replicator/configuration/index.xml" rel="self" type="application/rss+xml"/><item><title>Basic Configuration</title><link>https://choria-io.github.io/stream-replicator/configuration/basic/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://choria-io.github.io/stream-replicator/configuration/basic/index.html</guid><description>This section covers the basic information needed for copying streams from a Source to a Target.
Placement Architecture Generally it is best to place the Replicator nearest in terms of network latency to the Target.
When sampling data or tracking and publishing advisories it should be placed nearest to the Source. Advisories are also only Published to the Source so we&amp;rsquo;d want to give those the best chance of success possible by eliminating network issues.</description></item><item><title>Copying All Data</title><link>https://choria-io.github.io/stream-replicator/configuration/all/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://choria-io.github.io/stream-replicator/configuration/all/index.html</guid><description>The most common configuration is simply to copy all messages from a Source to a Target.
We won&amp;rsquo;t show the overall replication configuration, see Basic Configuration for an intro.
Configuring the Stream One can configure multiple streams and a Replicator will be configured for each Stream. Today the only mode we support is single worker, order preserving, copy from one Stream to another.
Sources and Targets A Source is where the messages are and a Target is where they are being copied.</description></item><item><title>Copying Samples of Data</title><link>https://choria-io.github.io/stream-replicator/configuration/sampling/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://choria-io.github.io/stream-replicator/configuration/sampling/index.html</guid><description>Overview It&amp;rsquo;s often a case that data in a specific location is produced frequently for maximal correctness of local data sources but in an archive or system that calls into those locations data freshness is not the most important property.
Stream Replicator supports sampling data from the Source and only sending a subset of data to the Target which can greatly improve the efficiency wrt network use and resources in the central archive.</description></item><item><title>HA Clustering</title><link>https://choria-io.github.io/stream-replicator/configuration/clustering/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://choria-io.github.io/stream-replicator/configuration/clustering/index.html</guid><description>Overview In all scenarios the Replicator supports running in highly available clustered modes.
Generally the replicator is designed to be strictly ordered, this means having active-active workers on a single stream is not possible without losing ordered messages. In this scenario we support partitioning streams and scaling out the copier workers horizontally and vertically with HA failover between nodes.
Combined this allows a very reliable and high performant replication infrastructure to be built.</description></item><item><title>Choria Registration Data</title><link>https://choria-io.github.io/stream-replicator/configuration/choria_registration/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://choria-io.github.io/stream-replicator/configuration/choria_registration/index.html</guid><description>We&amp;rsquo;ll show a full end to end walkthrough of building a centralised node metadata store for all your fleet nodes in multiple locations, including advisories about their availability.
While the central store will get data for any single node hourly it will also get advisories letting it know when a node has not been seen for 11 minutes and when a node has not been seen for a hour allowing an up to date node view to be maintained.</description></item></channel></rss>